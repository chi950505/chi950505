{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:23:14.760193Z","iopub.execute_input":"2025-02-22T17:23:14.760627Z","iopub.status.idle":"2025-02-22T17:23:14.765093Z","shell.execute_reply.started":"2025-02-22T17:23:14.760591Z","shell.execute_reply":"2025-02-22T17:23:14.764346Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhugging_face_token = user_secrets.get_secret(\"Hugging_Face_Token\")\nwnb_token = user_secrets.get_secret(\"wnb\")\n\nprint(hugging_face_token)\nprint(wnb_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:25:24.606551Z","iopub.execute_input":"2025-02-22T17:25:24.606856Z","iopub.status.idle":"2025-02-22T17:25:24.789786Z","shell.execute_reply.started":"2025-02-22T17:25:24.606833Z","shell.execute_reply":"2025-02-22T17:25:24.789072Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%capture\n\n# 安装 unsloth\n!pip install unsloth # install unsloth\n!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git # Also get the latest version Unsloth!\n# 重新安装 torchvision库（因为默认安装的版本不正确）\n!pip uninstall -y torch torchvision\n!pip install torch torchvision","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:32:36.346787Z","iopub.execute_input":"2025-02-22T17:32:36.347086Z","iopub.status.idle":"2025-02-22T17:36:18.834043Z","shell.execute_reply.started":"2025-02-22T17:32:36.347066Z","shell.execute_reply":"2025-02-22T17:36:18.832778Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 确认我们安装成功了unsloth\n!pip list | grep unsloth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:41:32.156899Z","iopub.execute_input":"2025-02-22T17:41:32.157208Z","iopub.status.idle":"2025-02-22T17:41:33.515267Z","shell.execute_reply.started":"2025-02-22T17:41:32.157182Z","shell.execute_reply":"2025-02-22T17:41:33.514294Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Modules for fine-tuning\nfrom unsloth import FastLanguageModel\nimport torch # Import PyTorch\nfrom trl import SFTTrainer # Trainer for supervised fine-tuning (SFT)\nfrom unsloth import is_bfloat16_supported # Checks if the hardware supports bfloat16 precision\n# Hugging Face modules\nfrom huggingface_hub import login # Lets you login to API\nfrom transformers import TrainingArguments # Defines training hyperparameters\nfrom datasets import load_dataset # Lets you load fine-tuning datasets\n# Import weights and biases\nimport wandb\n# Import kaggle secrets\nfrom kaggle_secrets import UserSecretsClient","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:42:03.999967Z","iopub.execute_input":"2025-02-22T17:42:04.000333Z","iopub.status.idle":"2025-02-22T17:42:32.297547Z","shell.execute_reply.started":"2025-02-22T17:42:04.000294Z","shell.execute_reply":"2025-02-22T17:42:32.296924Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize Hugging Face & WnB tokens\nuser_secrets = UserSecretsClient() # from kaggle_secrets import UserSecretsClient\nhugging_face_token = user_secrets.get_secret(\"Hugging_Face_Token\")\nwnb_token = user_secrets.get_secret(\"wnb\")\n\n# Login to Hugging Face\nlogin(hugging_face_token) # from huggingface_hub import login\n\n# Login to WnB\nwandb.login(key=wnb_token) # import wandb\nrun = wandb.init(\n    project='Fine-tune-DeepSeek-R1-Distill-Llama-8B on Medical COT Dataset_YouTube Walkthrough', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:45:11.905582Z","iopub.execute_input":"2025-02-22T17:45:11.905922Z","iopub.status.idle":"2025-02-22T17:45:24.652577Z","shell.execute_reply.started":"2025-02-22T17:45:11.905894Z","shell.execute_reply":"2025-02-22T17:45:24.651928Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m1048551870\u001b[0m (\u001b[33m1048551870-as\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250222_174518-bpzlpr8i</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/1048551870-as/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough/runs/bpzlpr8i' target=\"_blank\">deft-wildflower-5</a></strong> to <a href='https://wandb.ai/1048551870-as/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/1048551870-as/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough' target=\"_blank\">https://wandb.ai/1048551870-as/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/1048551870-as/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough/runs/bpzlpr8i' target=\"_blank\">https://wandb.ai/1048551870-as/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough/runs/bpzlpr8i</a>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# Set parameters\nmax_seq_length = 2048 # Define the maximum sequence length a model can handle (i.e. how many tokens can be processed at once)\ndtype = None # Set to default \nload_in_4bit = True # Enables 4 bit quantization — a memory saving optimization \n\n# Load the DeepSeek R1 model and tokenizer using unsloth — imported using: from unsloth import FastLanguageModel\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"unsloth/DeepSeek-R1-Distill-Llama-8B\",  # Load the pre-trained DeepSeek R1 model (8B parameter version)\n    max_seq_length=max_seq_length, # Ensure the model can process up to 2048 tokens at once\n    dtype=dtype, # Use the default data type (e.g., FP16 or BF16 depending on hardware support)\n    load_in_4bit=load_in_4bit, # Load the model in 4-bit quantization to save memory\n    token=hugging_face_token, # Use hugging face token\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:45:53.754285Z","iopub.execute_input":"2025-02-22T17:45:53.754611Z","iopub.status.idle":"2025-02-22T17:46:19.115487Z","shell.execute_reply.started":"2025-02-22T17:45:53.754587Z","shell.execute_reply":"2025-02-22T17:46:19.114855Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.49.0.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fd3995d51904b73a4d27187cc6ee299"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4485f8cfadec4fa2acd74a593da3bee6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/53.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af2a6a4816bc4ad5a102ef8711d2804f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbca0ad8c0e14c3483a341b606ea9769"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37a57a541fb94cf0b33a48680be93c60"}},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# Define a system prompt under prompt_style \nprompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \nWrite a response that appropriately completes the request. \nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n\n### Instruction:\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \nPlease answer the following medical question. \n\n### Question:\n{}\n\n### Response:\n<think>{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:47:00.956103Z","iopub.execute_input":"2025-02-22T17:47:00.956390Z","iopub.status.idle":"2025-02-22T17:47:00.961202Z","shell.execute_reply.started":"2025-02-22T17:47:00.956368Z","shell.execute_reply":"2025-02-22T17:47:00.960233Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Creating a test medical question for inference\nquestion = \"\"\"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or \n              sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, \n              what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\"\"\n\n# Enable optimized inference mode for Unsloth models (improves speed and efficiency)\nFastLanguageModel.for_inference(model)  # Unsloth has 2x faster inference!\n\n# Format the question using the structured prompt (`prompt_style`) and tokenize it\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")  # Convert input to PyTorch tensor & move to GPU\n\n# Generate a response using the model\noutputs = model.generate(\n    input_ids=inputs.input_ids, # Tokenized input question\n    attention_mask=inputs.attention_mask, # Attention mask to handle padding\n    max_new_tokens=1200, # Limit response length to 1200 tokens (to prevent excessive output)\n    use_cache=True, # Enable caching for faster inference\n)\n\n# Decode the generated output tokens into human-readable text\nresponse = tokenizer.batch_decode(outputs)\n\n# Extract and print only the relevant response part (after \"### Response:\")\nprint(response[0].split(\"### Response:\")[1])  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:47:25.563890Z","iopub.execute_input":"2025-02-22T17:47:25.564204Z","iopub.status.idle":"2025-02-22T17:48:16.350504Z","shell.execute_reply.started":"2025-02-22T17:47:25.564181Z","shell.execute_reply":"2025-02-22T17:48:16.349032Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nOkay, so I'm trying to figure out what cystometry would show for this 61-year-old woman. She's been having involuntary urine loss when she coughs or sneezes, but she doesn't leak at night. She's had a gynecological exam and a Q-tip test. I need to determine what cystometry would reveal about her residual volume and detrusor contractions.\n\nFirst, I should think about what causes involuntary urine loss during activities like coughing. That makes me think of stress urinary incontinence, especially since it's happening during activities that involve increased abdominal pressure. But since she doesn't leak at night, it's less likely to be a 24-hour leak, so maybe it's more related to stress rather than something like overactive bladder that affects both day and night.\n\nNext, the Q-tip test. I remember that the Q-tip is a disposable device used to measure bladder pressure. It's inserted into the urethra, and as the patient coughs, the pressure in the bladder can be measured. If the pressure is high, it might indicate that the bladder is not relaxing properly, which could be a sign of detrusor dysfunction.\n\nNow, moving on to cystometry, which is more detailed. It's also called a filling cystometry test. It measures how the bladder responds to filling and how it contracts. The test involves filling the bladder with a liquid, and then draining it while measuring pressure. This helps assess things like residual volume and detrusor contractions.\n\nSo, if during the Q-tip test they found high pressure readings, that might mean that when the bladder is full, it's not relaxing properly, leading to high pressure. This could indicate that there's a detrusor contraction happening even when the bladder is full, which might not be normal.\n\nIn the cystometry, residual volume is the amount of urine left in the bladder after emptying it completely. If the patient has some residual volume, that could contribute to her symptoms. But since she doesn't leak at night, maybe her residual volume isn't too high, but I'm not sure.\n\nDetrusor contractions are the involuntary tightening of the bladder muscle. If the detrusor is contracting too strongly, especially when the bladder is full, it can cause increased pressure, leading to urine leakage when the pressure exceeds the resistance of the urethra.\n\nPutting it all together, if the Q-tip test showed high bladder pressure, then the cystometry would likely show that the detrusor is contracting involuntarily, even when the bladder is full. This would suggest that the detrusor is not relaxing properly, which is causing the increased pressure leading to urine loss during activities like coughing.\n\nAs for the residual volume, if the patient can empty her bladder completely, the residual volume would be normal. However, if she can't empty completely, the residual volume might be elevated, contributing to her symptoms. But since she doesn't leak at night, the residual volume might not be a major issue here.\n\nSo, in summary, the cystometry would show that the detrusor is contracting involuntarily, leading to high bladder pressure, which explains her involuntary urine loss during coughing. The residual volume might be normal if she can empty completely, but the main issue is the detrusor dysfunction.\n</think>\n\nCystometry for this 61-year-old woman would likely reveal that her detrusor is contracting involuntarily, resulting in elevated bladder pressure. This is consistent with the findings from the Q-tip test, which indicated high bladder pressure during activities like coughing. The detrusor contractions are likely the primary cause of her symptoms, as they increase intravesicular pressure beyond the urethral resistance, leading to involuntary urine loss.\n\nRegarding residual volume, if the patient can empty her bladder completely, it would be within normal limits. However, if there is any residual volume that cannot be fully emptied, this could contribute to her symptoms. Since she does not experience leakage at night, it suggests that her residual volume is not significantly contributing to her condition. The primary issue appears to be the detrusor dysfunction causing increased pressure during activities.<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Creating a test medical question for inference\nquestion = \"\"\"你好吗?\"\"\"\n\n# Enable optimized inference mode for Unsloth models (improves speed and efficiency)\nFastLanguageModel.for_inference(model)  # Unsloth has 2x faster inference!\n\n# Format the question using the structured prompt (`prompt_style`) and tokenize it\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")  # Convert input to PyTorch tensor & move to GPU\n\n# Generate a response using the model\noutputs = model.generate(\n    input_ids=inputs.input_ids, # Tokenized input question\n    attention_mask=inputs.attention_mask, # Attention mask to handle padding\n    max_new_tokens=1200, # Limit response length to 1200 tokens (to prevent excessive output)\n    use_cache=True, # Enable caching for faster inference\n)\n\n# Decode the generated output tokens into human-readable text\nresponse = tokenizer.batch_decode(outputs)\n\n# Extract and print only the relevant response part (after \"### Response:\")\nprint(response[0].split(\"### Response:\")[1])  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:49:46.413151Z","iopub.execute_input":"2025-02-22T17:49:46.413502Z","iopub.status.idle":"2025-02-22T17:49:59.906089Z","shell.execute_reply.started":"2025-02-22T17:49:46.413475Z","shell.execute_reply":"2025-02-22T17:49:59.905219Z"}},"outputs":[{"name":"stdout","text":"\n<think>\n嗯，用户问“你好吗？”，看起来是想和我打招呼或者确认一下。作为一个医疗专家，我需要回应得体，但也要注意专业性。用户可能是想测试我的反应，或者是想聊天，但作为专家，我应该保持专业态度，同时提供帮助。\n\n首先，我应该礼貌回应，确认自己很好，然后问用户有什么问题需要帮助。这样既友好又专业，符合医疗咨询的场景。接下来，我需要等待用户提供更多的信息，才能给出准确的建议或解答。\n\n可能用户的问题涉及到健康问题，比如症状、治疗方案或者诊断建议。所以，我需要准备好各种可能性，并根据用户提供的信息给予相应的回应。同时，要保持语气友好，让用户感到被重视和支持。\n\n总之，我的回应应该包括确认状态、询问问题，并准备好接下来提供帮助。这样既符合用户的需求，又保持了专业性。\n</think>\n\n你好！我很好。有什么我可以帮助你的吗？<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Updated training prompt style to add </think> tag \ntrain_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \nWrite a response that appropriately completes the request. \nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n\n### Instruction:\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \nPlease answer the following medical question. \n\n### Question:\n{}\n\n### Response:\n<think>\n{}\n</think>\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T18:03:36.317563Z","iopub.execute_input":"2025-02-22T18:03:36.317930Z","iopub.status.idle":"2025-02-22T18:03:36.322804Z","shell.execute_reply.started":"2025-02-22T18:03:36.317902Z","shell.execute_reply":"2025-02-22T18:03:36.321903Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Download the dataset using Hugging Face — function imported using from datasets import load_dataset\ndataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\",\"en\", split = \"train[0:500]\",trust_remote_code=True) # Keep only first 500 rows\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T18:03:57.036331Z","iopub.execute_input":"2025-02-22T18:03:57.036663Z","iopub.status.idle":"2025-02-22T18:04:00.231606Z","shell.execute_reply.started":"2025-02-22T18:03:57.036639Z","shell.execute_reply":"2025-02-22T18:04:00.230776Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.65k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d9a4442fe4e41268b80bea83ae28c7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"medical_o1_sft.json:   0%|          | 0.00/74.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c9b2e6eeb6f4a71a46eab21c30cc5c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25371 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60f17796d9ae4409aed697836ad05b51"}},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Question', 'Complex_CoT', 'Response'],\n    num_rows: 500\n})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"# Show an entry from the dataset\ndataset[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T18:04:14.874253Z","iopub.execute_input":"2025-02-22T18:04:14.874567Z","iopub.status.idle":"2025-02-22T18:04:14.882821Z","shell.execute_reply.started":"2025-02-22T18:04:14.874543Z","shell.execute_reply":"2025-02-22T18:04:14.881896Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'Question': 'A 45-year-old man with a history of alcohol use, who has been abstinent for the past 10 years, presents with sudden onset dysarthria, shuffling gait, and intention tremors. Given this clinical presentation and history, what is the most likely diagnosis?',\n 'Complex_CoT': \"Alright, let’s break this down. We have a 45-year-old man here, who suddenly starts showing some pretty specific symptoms: dysarthria, shuffling gait, and those intention tremors. This suggests something's going wrong with motor control, probably involving the cerebellum or its connections.\\n\\nNow, what's intriguing is that he's had a history of alcohol use, but he's been off it for the past 10 years. Alcohol can do a number on the cerebellum, leading to degeneration, and apparently, the effects can hang around or even appear long after one stops drinking.\\n\\nAt first glance, these symptoms look like they could be some kind of chronic degeneration, maybe something like alcoholic cerebellar degeneration, but hold on. This looks different. The symptoms just came on all of a sudden. Chronic degenerations typically have a more gradual onset.\\n\\nOkay, let’s reconsider this sudden nature. It’s making me think of something more acute, more rapid onset. Hmm, if we dig back into his history of drinking, there might have been some damage done, leading to nutritional deficiencies, like a lack of thiamine.\\n\\nWernicke’s encephalopathy is a classic possibility here. That condition pops up due to thiamine deficiency, often after a history of alcohol use. It’s known for causing ataxia, confusion, and eye movement issues. However, he’s not showing the full triad of symptoms; there's no mention of confusion or eye problems, so maybe it doesn’t fit perfectly.\\n\\nOh, wait a second, maybe we're missing something simpler. Given the acute nature of the symptoms, maybe this is more in line with something like a stroke. Sudden onset can definitely suggest a vascular event. With his alcohol history, he’s at risk for things like high blood pressure, which can increase stroke risk.\\n\\nIn particular, lacunar strokes can mess with motor coordination, speech, the works. These are small, but significant enough to cause these exact symptoms: dysarthria, tremors, and a shuffling gait.\\n\\nBut hang on, what if there’s another angle we’re missing? Chronic alcohol effects might still play a role here, just in a different way. There’s a condition called acquired hepatocerebral degeneration. This can happen in people with a history of liver disease due to alcohol, even years after they’ve quit. It can result in symptoms like these because of how substances get deposited in the brain.\\n\\nLinking this back to our patient, his history with alcohol could’ve led to some liver issues, and now, here we are with these symptoms showing up suddenly. Makes sense, right? So, considering everything, acquired hepatocerebral degeneration seems to fit quite nicely. That’s probably our most fitting diagnosis for this situation.\",\n 'Response': \"Considering the clinical presentation of sudden onset dysarthria, shuffling gait, and intention tremors in a 45-year-old man with a history of alcohol use who has been abstinent for the past 10 years, the most likely diagnosis is acquired hepatocerebral degeneration.\\n\\nThis condition is associated with chronic liver disease, which can often be a consequence of long-term alcohol use. Despite the patient's abstinence from alcohol for a decade, previous alcohol use may have led to underlying liver dysfunction. This dysfunction, even if subclinical, can cause encephalopathy due to the accumulation of neurotoxic substances that affect the brain. The sudden onset of these neurological symptoms aligns with how acquired hepatocerebral degeneration can manifest, making it a probable diagnosis in this scenario.\"}"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# We need to format the dataset to fit our prompt training style \nEOS_TOKEN = tokenizer.eos_token  # Define EOS_TOKEN which the model when to stop generating text during training\nEOS_TOKEN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T18:05:05.272463Z","iopub.execute_input":"2025-02-22T18:05:05.272946Z","iopub.status.idle":"2025-02-22T18:05:05.280298Z","shell.execute_reply.started":"2025-02-22T18:05:05.272906Z","shell.execute_reply":"2025-02-22T18:05:05.279434Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"'<｜end▁of▁sentence｜>'"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"# Define formatting prompt function\ndef formatting_prompts_func(examples):  # Takes a batch of dataset examples as input\n    inputs = examples[\"Question\"]       # Extracts the medical question from the dataset\n    cots = examples[\"Complex_CoT\"]      # Extracts the chain-of-thought reasoning (logical step-by-step explanation)\n    outputs = examples[\"Response\"]      # Extracts the final model-generated response (answer)\n    \n    texts = []  # Initializes an empty list to store the formatted prompts\n    \n    # Iterate over the dataset, formatting each question, reasoning step, and response\n    for input, cot, output in zip(inputs, cots, outputs):  \n        text = train_prompt_style.format(input, cot, output) + EOS_TOKEN  # Insert values into prompt template & append EOS token\n        texts.append(text)  # Add the formatted text to the list\n\n    return {\n        \"text\": texts,  # Return the newly formatted dataset with a \"text\" column containing structured prompts\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T18:05:18.316632Z","iopub.execute_input":"2025-02-22T18:05:18.317050Z","iopub.status.idle":"2025-02-22T18:05:18.323385Z","shell.execute_reply.started":"2025-02-22T18:05:18.317008Z","shell.execute_reply":"2025-02-22T18:05:18.322536Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Update dataset formatting\ndataset_finetune = dataset.map(formatting_prompts_func, batched = True)\ndataset_finetune[\"text\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T18:05:30.001203Z","iopub.execute_input":"2025-02-22T18:05:30.001505Z","iopub.status.idle":"2025-02-22T18:05:30.049324Z","shell.execute_reply.started":"2025-02-22T18:05:30.001482Z","shell.execute_reply":"2025-02-22T18:05:30.048515Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdd9fbd737174dc2867e5a383b1adbbb"}},"metadata":{}},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"\"Below is an instruction that describes a task, paired with an input that provides further context. \\nWrite a response that appropriately completes the request. \\nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\\n\\n### Instruction:\\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \\nPlease answer the following medical question. \\n\\n### Question:\\nA 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, what would cystometry most likely reveal about her residual volume and detrusor contractions?\\n\\n### Response:\\n<think>\\nOkay, let's think about this step by step. There's a 61-year-old woman here who's been dealing with involuntary urine leakages whenever she's doing something that ups her abdominal pressure like coughing or sneezing. This sounds a lot like stress urinary incontinence to me. Now, it's interesting that she doesn't have any issues at night; she isn't experiencing leakage while sleeping. This likely means her bladder's ability to hold urine is fine when she isn't under physical stress. Hmm, that's a clue that we're dealing with something related to pressure rather than a bladder muscle problem. \\n\\nThe fact that she underwent a Q-tip test is intriguing too. This test is usually done to assess urethral mobility. In stress incontinence, a Q-tip might move significantly, showing urethral hypermobility. This kind of movement often means there's a weakness in the support structures that should help keep the urethra closed during increases in abdominal pressure. So, that's aligning well with stress incontinence.\\n\\nNow, let's think about what would happen during cystometry. Since stress incontinence isn't usually about sudden bladder contractions, I wouldn't expect to see involuntary detrusor contractions during this test. Her bladder isn't spasming or anything; it's more about the support structure failing under stress. Plus, she likely empties her bladder completely because stress incontinence doesn't typically involve incomplete emptying. So, her residual volume should be pretty normal. \\n\\nAll in all, it seems like if they do a cystometry on her, it will likely show a normal residual volume and no involuntary contractions. Yup, I think that makes sense given her symptoms and the typical presentations of stress urinary incontinence.\\n</think>\\nCystometry in this case of stress urinary incontinence would most likely reveal a normal post-void residual volume, as stress incontinence typically does not involve issues with bladder emptying. Additionally, since stress urinary incontinence is primarily related to physical exertion and not an overactive bladder, you would not expect to see any involuntary detrusor contractions during the test.<｜end▁of▁sentence｜>\""},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"FastLanguageModel.for_training(model)\n\n# Apply LoRA (Low-Rank Adaptation) fine-tuning to the model \nmodel_lora = FastLanguageModel.get_peft_model(\n    model,\n    r=16,  # LoRA rank: Determines the size of the trainable adapters (higher = more parameters, lower = more efficiency)\n    target_modules=[  # List of transformer layers where LoRA adapters will be applied\n        \"q_proj\",   # Query projection in the self-attention mechanism\n        \"k_proj\",   # Key projection in the self-attention mechanism\n        \"v_proj\",   # Value projection in the self-attention mechanism\n        \"o_proj\",   # Output projection from the attention layer\n        \"gate_proj\",  # Used in feed-forward layers (MLP)\n        \"up_proj\",    # Part of the transformer’s feed-forward network (FFN)\n        \"down_proj\",  # Another part of the transformer’s FFN\n    ],\n    lora_alpha=16,  # Scaling factor for LoRA updates (higher values allow more influence from LoRA layers)\n    lora_dropout=0,  # Dropout rate for LoRA layers (0 means no dropout, full retention of information)\n    bias=\"none\",  # Specifies whether LoRA layers should learn bias terms (setting to \"none\" saves memory)\n    use_gradient_checkpointing=\"unsloth\",  # Saves memory by recomputing activations instead of storing them (recommended for long-context fine-tuning)\n    random_state=3407,  # Sets a seed for reproducibility, ensuring the same fine-tuning behavior across runs\n    use_rslora=False,  # Whether to use Rank-Stabilized LoRA (disabled here, meaning fixed-rank LoRA is used)\n    loftq_config=None,  # Low-bit Fine-Tuning Quantization (LoFTQ) is disabled in this configuration\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T18:05:48.560933Z","iopub.execute_input":"2025-02-22T18:05:48.561256Z","iopub.status.idle":"2025-02-22T18:05:55.215068Z","shell.execute_reply.started":"2025-02-22T18:05:48.561233Z","shell.execute_reply":"2025-02-22T18:05:55.213561Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2025.2.15 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Initialize the fine-tuning trainer — Imported using from trl import SFTTrainer\ntrainer = SFTTrainer(\n    model=model_lora,  # The model to be fine-tuned\n    tokenizer=tokenizer,  # Tokenizer to process text inputs\n    train_dataset=dataset_finetune,  # Dataset used for training\n    dataset_text_field=\"text\",  # Specifies which field in the dataset contains training text\n    max_seq_length=max_seq_length,  # Defines the maximum sequence length for inputs\n    dataset_num_proc=2,  # Uses 2 CPU threads to speed up data preprocessing\n\n    # Define training arguments\n    args=TrainingArguments(\n        per_device_train_batch_size=2,  # Number of examples processed per device (GPU) at a time\n        gradient_accumulation_steps=4,  # Accumulate gradients over 4 steps before updating weights\n        num_train_epochs=1, # Full fine-tuning run\n        warmup_steps=5,  # Gradually increases learning rate for the first 5 steps\n        max_steps=30,  # Limits training to 60 steps (useful for debugging; increase for full fine-tuning)\n        learning_rate=2e-4,  # Learning rate for weight updates (tuned for LoRA fine-tuning)\n        fp16=not is_bfloat16_supported(),  # Use FP16 (if BF16 is not supported) to speed up training\n        bf16=is_bfloat16_supported(),  # Use BF16 if supported (better numerical stability on newer GPUs)\n        logging_steps=10,  # Logs training progress every 10 steps\n        optim=\"adamw_8bit\",  # Uses memory-efficient AdamW optimizer in 8-bit mode\n        weight_decay=0.01,  # Regularization to prevent overfitting\n        lr_scheduler_type=\"linear\",  # Uses a linear learning rate schedule\n        seed=3407,  # Sets a fixed seed for reproducibility\n        output_dir=\"outputs\",  # Directory where fine-tuned model checkpoints will be saved\n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T18:06:28.366374Z","iopub.execute_input":"2025-02-22T18:06:28.366752Z","iopub.status.idle":"2025-02-22T18:06:34.448721Z","shell.execute_reply.started":"2025-02-22T18:06:28.366720Z","shell.execute_reply":"2025-02-22T18:06:34.447967Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Converting train dataset to ChatML (num_proc=2):   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a79974e41ad40c79d2fe12617863f32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset (num_proc=2):   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f76d44fbfede4bc4844173029d8467b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset (num_proc=2):   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b34b7bc259b24c09aa7bad17bde0d4f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset (num_proc=2):   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac69ad1f341e491981a436c497c1d5d7"}},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"# Start the fine-tuning process\ntrainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T18:07:30.748503Z","iopub.execute_input":"2025-02-22T18:07:30.748908Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 500 | Num Epochs = 1\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 8 | Total steps = 30\n \"-____-\"     Number of trainable parameters = 41,943,040\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='25' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [25/30 08:24 < 01:49, 0.05 it/s, Epoch 0.38/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.919900</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.468300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null}]}